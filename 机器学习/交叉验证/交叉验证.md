### 留出法（hold out）
------
直接将数据集D划分为两个互斥的集合，其中一个作为训练集S，一个作为验证集T。在S上训练出模型后，用T来评估其测试误差，作为对泛化误差的估计。

**注意**：

1. 划分数据的时候要保持数据分布的一致性（分层采样）。
2. 对数据的不同划分方式也会对结果产生影响（比如选取前30%和后30%的数据作为验证集），所以一般要多次划分、重复试验，取平均结果。

**如果数据集较大**，则**可以只使用留出法**，比如**深度学习**任务。

**如果数据集较小，**留出法就会存在问题：

1. 如果令S包含绝大多数样本，则训练出来的模型会更接近D训练出来的模型，但是T就比较小，降低了评估结果的稳定性。
2. 如果令T多包含一些样本，则S和D训练出来的模型有可能有较大差别，降低了评估结果的保真性（fidelity）。

### 交叉验证法（cross validation）
------
将数据集D划分为k个大小相似的互斥子集，每个子集Di都尽可能保持数据分布的一致性，然后每次将k-1个子集的并集作为训练集，余下的那个子集作为验证集，得到k组训练/验证集，进行k次训练和评估，返回k个测试结果的均值。

注意：

1. 与留出法相似，为了减小因为数据划分方式的不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，也就是一共训练/测试了p*k次。

### 选择模型的方法：
------
- 简单交叉验证：

1. 将原始training dataset分为training dataset和validation set
2. 通过training dataset来训练不同模型
3. 通过validation dataset检验模型，选择误差最小的模型

- k折交叉验证：

1. 将training dataset随机划分为k个互不相交、大小相同的子集
2. 将k-1个子集的数据作为training dataset训练模型，将余下的子集作为validation dataset检验模型
3. 重复上个步骤k次，选择k次检验中平均测试误差最小的模型

- 留一交叉验证：

1. k折交叉验证的特殊情况，k = N，N为给定数据集的容量

选出模型后，根据K折训练得出的经验训练轮数，使用原始training dataset重新训练选择的模型（或者直接选择平均K次训练的模型参数），并test dataset评估模型，从k+1个模型中选取最优作为最终模型。

注：

模型选择的范围包括 1.不同的基准模型 2.同一基准模型下不同的超参。

使用简单交叉验证需要训练M次模型，使用k折交叉验证需要训练K*M次模型，M为待选模型的数量。

通常深度学习不需要使用k折交叉验证，只有在模型较为简单，数据不充足的情况下使用。

### K折交叉验证的K如何选择？

------

**经验取10.一般来说k越大越好，但也得考虑所带来的额外计算开销。**

- 当k=1时，即完全不使用交叉验证，所有数据都用于训练，这个时候模型很容易过拟合，会出现低偏差、高方差的情况。

- [x] todo ==*？全部用于训练不应该是比留一法更极端的做法么 k=2时一半训练一半预测，偏差？方差？*== 

- 当k=N时，即留一法，随着k的增大，从单一模型看是偏差逐渐减小，方差逐渐增大；但从总体模型来看，是偏差逐渐增大，方差逐渐减小。

- [x] ==总体模型没看懂？==

https://zhuanlan.zhihu.com/p/31924220

------

~~**存疑：**~~

~~k折交叉验证是先随机划分训练集和测试集，然后在训练集上随机划分K份。那其实测试集是固定的，而且只随机划分了一次，那如何确保测试集的数据多样性？也可能都是简单样本或者困难样本？~~

~~通常来讲，数据训练集和测试集是分开的，测试集的标签信息只在数据集维护者手里。测试集是用来测试模型的泛化能力的（泛化误差包括方差、偏差、噪声），通常情况下较大，不大会存在数据分布不均的问题。~~

~~https://zhuanlan.zhihu.com/p/83841282~~

~~按照该文中的方法，将整个数据集随机划分为k份，一份作为测试集，k-1份作为训练集，再从训练集中随机划分出一部分（5%）作为验证集。这样就保证了所有数据都在测试集中出现过。~~

~~但这样存在的问题是验证集过小，数据波动性较大，验证集是用来寻找合适超参的，这样可行？可能存在问题。~~

------

### 参考：

统计学习方法 p24

https://www.zhihu.com/question/39259296

https://zhuanlan.zhihu.com/p/31924220

